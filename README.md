# ğŸ¤– The Brain: Intelligent LangChain RAG Chatbot

![Python](https://img.shields.io/badge/Python-3.10%2B-blue?style=for-the-badge&logo=python&logoColor=white)
![LangChain](https://img.shields.io/badge/LangChain-ğŸ¦œï¸ğŸ”—-green?style=for-the-badge)
![ChromaDB](https://img.shields.io/badge/ChromaDB-Vector_Store-purple?style=for-the-badge)

> *"I don't just answer questions. I understand context."*

## ğŸš€ Overview
This is not just another chatbot. This is a **Context-Aware AI Assistant** built using **LangChain**. It uses **Retrieval-Augmented Generation (RAG)** to ingest custom data, store it as vector embeddings in **ChromaDB**, and retrieve precise answers. It bridges the gap between raw data and intelligent conversation.

**Built for efficiency. Optimized for accuracy.**

## ğŸ§  Key Features
* **RAG Architecture:** Retrieves information from your own documents, not just the model's training data.
* **Vector Memory:** Uses **ChromaDB** to store and query high-dimensional vector embeddings.
* **Context Retention:** Remembers the conversation flow (Memory buffers).
* **Modular Design:** Clean separation of ingestion, retrieval, and generation logic.

## ğŸ› ï¸ Tech Stack
* **Core Framework:** [LangChain](https://python.langchain.com/) ğŸ¦œï¸ğŸ”—
* **Language:** Python ğŸ
* **Vector Database:** ChromaDB ğŸ³ï¸â€ğŸŒˆ
* **LLM Engine:** (e.g., OpenAI GPT / Llama 2 / Gemini)
* **Environment:** VS Code

## ğŸ“‚ Project Structure
```bash
LangChain/
â”œâ”€â”€ venv/               # Virtual Environment (Ignored by Git)
â””â”€â”€ chatbot/            # The Main Application
    â”œâ”€â”€ app.py          # Main application logic
    â”œâ”€â”€ chroma_db/      # Vector Storage (Ignored by Git)
    â”œâ”€â”€ .env            # API Keys (Ignored by Git)
    â”œâ”€â”€ .gitignore      # The Security Guard
    â””â”€â”€ README.md       # You are here